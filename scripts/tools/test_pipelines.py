#!/usr/bin/env python3
"""
Pipeline éªŒè¯å’Œè°ƒè¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. åˆ é™¤æ—§çš„ workflow æ–‡ä»¶
2. ä½¿ç”¨è„šæ‰‹æ¶å·¥å…·é‡æ–°ç”Ÿæˆ workflow
3. éªŒè¯ç”Ÿæˆçš„ workflow æ–‡ä»¶
4. å¯é€‰ï¼šè§¦å‘ workflow è¿›è¡Œåœ¨çº¿æµ‹è¯•
5. ç›‘æ§ workflow æ‰§è¡ŒçŠ¶æ€
6. åˆ†æå¤±è´¥åŸå› 

ç”¨æ³•:
  python scripts/test_pipelines.py [options]

é€‰é¡¹:
  --pipeline <name>    æŒ‡å®šè¦æµ‹è¯•çš„ Pipeline ç±»åï¼ˆå¯å¤šæ¬¡æŒ‡å®šï¼‰
  --all                æµ‹è¯•æ‰€æœ‰ Pipeline
  --trigger            è§¦å‘ workflow è¿›è¡Œåœ¨çº¿æµ‹è¯•
  --watch              ç›‘æ§ workflow æ‰§è¡ŒçŠ¶æ€
  --clean              åˆ é™¤æ—§çš„ workflow æ–‡ä»¶
  --verify             ä»…éªŒè¯ç”Ÿæˆçš„ workflow æ–‡ä»¶ï¼Œä¸è§¦å‘æµ‹è¯•
"""

import sys
import os
import argparse
import subprocess
import yaml
import time
from pathlib import Path
import importlib.util
import re


def detect_project_root() -> Path:
    """æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•"""
    current = Path.cwd()
    while current != current.parent:
        if (current / "package.json").exists() or (current / "environment.yml").exists():
            return current
        current = current.parent
    return Path.cwd()


def find_pipeline_files(project_root: Path) -> list:
    """æŸ¥æ‰¾æ‰€æœ‰ Pipeline æ–‡ä»¶"""
    # Pipeline æ–‡ä»¶åœ¨ python/src/pipelines/ ç›®å½•
    python_dir = project_root / "python"
    pipelines_dir = python_dir / "src" / "pipelines"
    if not pipelines_dir.exists():
        return []
    
    files = []
    for file_path in pipelines_dir.rglob("*.py"):
        if not file_path.name.startswith("_"):
            files.append(file_path)
    
    return files


def extract_class_name(file_path: Path) -> str:
    """ä»æ–‡ä»¶å†…å®¹ä¸­æå– Pipeline ç±»å"""
    try:
        content = file_path.read_text(encoding="utf-8")
        # æŸ¥æ‰¾ class XxxPipeline æ¨¡å¼
        match = re.search(r"class\s+(\w+Pipeline)\s*[\(:]", content)
        if match:
            return match.group(1)
    except Exception:
        pass
    return None


def clean_workflows(workflows_dir: Path) -> None:
    """åˆ é™¤æ—§çš„ workflow æ–‡ä»¶"""
    print("ğŸ§¹ æ¸…ç†æ—§çš„ workflow æ–‡ä»¶...")
    for file_path in workflows_dir.glob("*.yml"):
        file_path.unlink()
        print(f"   âœ“ åˆ é™¤: {file_path.name}")
    for file_path in workflows_dir.glob("*.yaml"):
        file_path.unlink()
        print(f"   âœ“ åˆ é™¤: {file_path.name}")


def generate_workflow(
    project_root: Path,
    pipeline_name: str,
    workflows_dir: Path
) -> Path:
    """ç”Ÿæˆ workflow æ–‡ä»¶"""
    print(f"ğŸ“ ç”Ÿæˆ workflow: {pipeline_name}...")
    
    # ç”Ÿæˆ workflow æ–‡ä»¶å
    workflow_name = (
        pipeline_name.replace("Pipeline", "")
        .replace("_", "-")
        .lower()
    )
    output_path = workflows_dir / f"{workflow_name}.yml"
    
    # ä½¿ç”¨è„šæ‰‹æ¶å·¥å…·ç”Ÿæˆ
    # éœ€è¦ä» python/ ç›®å½•è¿è¡Œè„šæ‰‹æ¶å·¥å…·
    python_dir = project_root / "python"
    scaffold_cmd = [
        sys.executable,
        "-m", "src.scaffold",
        "--pipeline", pipeline_name,
        "--output", str(output_path.relative_to(project_root)),
    ]
    
    if output_path.exists():
        scaffold_cmd.append("--update")
    
    try:
        result = subprocess.run(
            scaffold_cmd,
            cwd=python_dir,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0 and output_path.exists():
            print(f"   âœ“ æˆåŠŸ: {output_path.relative_to(project_root)}")
            return output_path
        else:
            print(f"   âŒ ç”Ÿæˆå¤±è´¥: {result.stderr}")
            return None
    except Exception as e:
        print(f"   âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None


def verify_workflow(workflow_path: Path) -> tuple:
    """éªŒè¯ workflow æ–‡ä»¶"""
    errors = []
    
    try:
        with open(workflow_path, "r", encoding="utf-8") as f:
            workflow = yaml.safe_load(f)
        
        # æ£€æŸ¥åŸºæœ¬ç»“æ„
        if not workflow.get("name"):
            errors.append("ç¼ºå°‘ workflow åç§°")
        if not workflow.get("on"):
            errors.append("ç¼ºå°‘è§¦å‘æ¡ä»¶")
        if not workflow.get("jobs"):
            errors.append("ç¼ºå°‘ jobs å®šä¹‰")
        
        # æ£€æŸ¥ Pipeline æ‰§è¡Œæ­¥éª¤
        content = workflow_path.read_text(encoding="utf-8")
        if "python -c" not in content and "Run " not in content:
            errors.append("ç¼ºå°‘ Pipeline æ‰§è¡Œæ­¥éª¤")
        
        return len(errors) == 0, errors
    except Exception as e:
        return False, [f"YAML è§£æé”™è¯¯: {str(e)}"]


def main():
    parser = argparse.ArgumentParser(description="Pipeline éªŒè¯å’Œè°ƒè¯•è„šæœ¬")
    parser.add_argument("--pipeline", action="append", help="Pipeline ç±»åï¼ˆå¯å¤šæ¬¡æŒ‡å®šï¼‰")
    parser.add_argument("--all", action="store_true", help="æµ‹è¯•æ‰€æœ‰ Pipeline")
    parser.add_argument("--trigger", action="store_true", help="è§¦å‘ workflow è¿›è¡Œåœ¨çº¿æµ‹è¯•")
    parser.add_argument("--watch", action="store_true", help="ç›‘æ§ workflow æ‰§è¡ŒçŠ¶æ€")
    parser.add_argument("--clean", action="store_true", help="åˆ é™¤æ—§çš„ workflow æ–‡ä»¶")
    parser.add_argument("--verify", action="store_true", help="ä»…éªŒè¯ç”Ÿæˆçš„ workflow æ–‡ä»¶")
    
    args = parser.parse_args()
    
    project_root = detect_project_root()
    workflows_dir = project_root / ".github" / "workflows"
    workflows_dir.mkdir(parents=True, exist_ok=True)
    
    # æ¸…ç†æ—§çš„ workflow æ–‡ä»¶
    if args.clean:
        clean_workflows(workflows_dir)
    
    # ç¡®å®šè¦æµ‹è¯•çš„ Pipeline
    pipelines = []
    if args.all:
        pipeline_files = find_pipeline_files(project_root)
        for file_path in pipeline_files:
            class_name = extract_class_name(file_path)
            if class_name:
                pipelines.append(class_name)
    elif args.pipeline:
        pipelines = args.pipeline
    else:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®š --pipeline æˆ– --all")
        sys.exit(1)
    
    if not pipelines:
        print("âŒ æœªæ‰¾åˆ° Pipeline")
        sys.exit(1)
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(pipelines)} ä¸ª Pipeline:")
    for pipeline in pipelines:
        print(f"   - {pipeline}")
    print()
    
    # ç”Ÿæˆ workflow
    generated_workflows = []
    for pipeline_name in pipelines:
        workflow_path = generate_workflow(project_root, pipeline_name, workflows_dir)
        if workflow_path:
            generated_workflows.append(workflow_path)
    
    if not generated_workflows:
        print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½• workflow")
        sys.exit(1)
    
    print(f"\nâœ… æˆåŠŸç”Ÿæˆ {len(generated_workflows)} ä¸ª workflow\n")
    
    # éªŒè¯ workflow
    if args.verify or not args.trigger:
        print("ğŸ” éªŒè¯ workflow æ–‡ä»¶...")
        all_valid = True
        for workflow_path in generated_workflows:
            valid, errors = verify_workflow(workflow_path)
            if valid:
                print(f"   âœ“ {workflow_path.name}: éªŒè¯é€šè¿‡")
            else:
                print(f"   âŒ {workflow_path.name}: éªŒè¯å¤±è´¥")
                for error in errors:
                    print(f"      - {error}")
                all_valid = False
        
        if not all_valid:
            print("\nâŒ éƒ¨åˆ† workflow éªŒè¯å¤±è´¥")
            sys.exit(1)
        
        print("\nâœ… æ‰€æœ‰ workflow éªŒè¯é€šè¿‡")
    
    # è§¦å‘å’Œç›‘æ§ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if args.trigger:
        print("\nğŸš€ è§¦å‘ workflow è¿›è¡Œåœ¨çº¿æµ‹è¯•...")
        print("   æ³¨æ„: æ­¤åŠŸèƒ½éœ€è¦ GitHub CLI (gh) å’Œæ¨é€ä»£ç åˆ°è¿œç¨‹ä»“åº“")
        # è¿™é‡Œå¯ä»¥æ·»åŠ è§¦å‘é€»è¾‘
        # ç”±äºéœ€è¦ GitHub CLIï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        print("   âš ï¸  è§¦å‘åŠŸèƒ½éœ€è¦æ‰‹åŠ¨å®ç°æˆ–ä½¿ç”¨ GitHub CLI")


if __name__ == "__main__":
    main()

